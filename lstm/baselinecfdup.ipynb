{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "341f931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._split.StratifiedGroupKFold'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "print(StratifiedGroupKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e4b8533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all shape: torch.Size([173, 32, 53])\n",
      "y_all shape: torch.Size([173])\n",
      "groups shape: torch.Size([173])\n",
      "meta: {'window_size': 32, 'stride_size': 16}\n",
      "ALL class distribution:\n",
      "  class 0: 21\n",
      "  class 1: 79\n",
      "  class 2: 73\n",
      "\n",
      "Unique group ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "Number of groups: 15\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"../csi_dataset/csi_windows_w32_s16.pt\"  # path ตามของคุณ\n",
    "\n",
    "obj = torch.load(DATA_PATH, map_location=\"cpu\")\n",
    "\n",
    "X_all = obj[\"X\"]         # (N, seq_len, n_features) เป็น torch.Tensor\n",
    "y_all = obj[\"y\"]         # (N,)\n",
    "groups = obj[\"group\"]    # (N,) group id ต่อ window\n",
    "\n",
    "print(\"X_all shape:\", X_all.shape)\n",
    "print(\"y_all shape:\", y_all.shape)\n",
    "print(\"groups shape:\", groups.shape)\n",
    "\n",
    "if \"meta\" in obj:\n",
    "    print(\"meta:\", obj[\"meta\"])\n",
    "\n",
    "def show_class_dist(name, y):\n",
    "    y_np = y.cpu().numpy() if isinstance(y, torch.Tensor) else np.array(y)\n",
    "    uniq, cnt = np.unique(y_np, return_counts=True)\n",
    "    print(f\"{name} class distribution:\")\n",
    "    for u, c in zip(uniq, cnt):\n",
    "        print(f\"  class {u}: {c}\")\n",
    "    print()\n",
    "\n",
    "show_class_dist(\"ALL\", y_all)\n",
    "\n",
    "# groups สำหรับ sklearn → ใช้ numpy\n",
    "if isinstance(groups, torch.Tensor):\n",
    "    groups = groups.numpy()\n",
    "\n",
    "print(\"Unique group ids:\", np.unique(groups))\n",
    "print(\"Number of groups:\", len(np.unique(groups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19a199ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 0: total 16\n",
      "  class 2: 16\n",
      "\n",
      "Group 1: total 14\n",
      "  class 2: 14\n",
      "\n",
      "Group 2: total 14\n",
      "  class 2: 14\n",
      "\n",
      "Group 3: total 15\n",
      "  class 2: 15\n",
      "\n",
      "Group 4: total 14\n",
      "  class 2: 14\n",
      "\n",
      "Group 5: total 17\n",
      "  class 1: 17\n",
      "\n",
      "Group 6: total 14\n",
      "  class 1: 14\n",
      "\n",
      "Group 7: total 16\n",
      "  class 1: 16\n",
      "\n",
      "Group 8: total 15\n",
      "  class 1: 15\n",
      "\n",
      "Group 9: total 17\n",
      "  class 1: 17\n",
      "\n",
      "Group 10: total 4\n",
      "  class 0: 4\n",
      "\n",
      "Group 11: total 5\n",
      "  class 0: 5\n",
      "\n",
      "Group 12: total 4\n",
      "  class 0: 4\n",
      "\n",
      "Group 13: total 4\n",
      "  class 0: 4\n",
      "\n",
      "Group 14: total 4\n",
      "  class 0: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_group_class_distribution(groups, y_all):\n",
    "    group_ids = np.unique(groups)\n",
    "    for g in group_ids:\n",
    "        mask = (groups == g)\n",
    "        y_g = y_all[mask]\n",
    "        y_np = y_g.cpu().numpy() if isinstance(y_g, torch.Tensor) else np.array(y_g)\n",
    "        uniq, cnt = np.unique(y_np, return_counts=True)\n",
    "        print(f\"\\nGroup {g}: total {len(y_g)}\")\n",
    "        for u, c in zip(uniq, cnt):\n",
    "            print(f\"  class {u}: {c}\")\n",
    "\n",
    "show_group_class_distribution(groups, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8625df67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected random_state: 2\n",
      "X_temp: torch.Size([137, 32, 53])\n",
      "X_test: torch.Size([36, 32, 53])\n",
      "TEMP class distribution:\n",
      "  class 0: 16\n",
      "  class 1: 62\n",
      "  class 2: 59\n",
      "\n",
      "TEST class distribution:\n",
      "  class 0: 5\n",
      "  class 1: 17\n",
      "  class 2: 14\n",
      "\n",
      "TEMP groups: [ 0  1  2  3  6  7  8  9 10 12 13 14]\n",
      "TEST groups: [ 4  5 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# แปลง groups เป็น numpy สำหรับ sklearn/group indexing\n",
    "if isinstance(groups, torch.Tensor):\n",
    "    groups_np = groups.detach().cpu().numpy()\n",
    "else:\n",
    "    groups_np = np.asarray(groups)\n",
    "\n",
    "# แปลง y_all เป็น numpy เฉพาะเพื่อเช็ค class coverage ใน test\n",
    "if isinstance(y_all, torch.Tensor):\n",
    "    y_all_np = y_all.detach().cpu().numpy()\n",
    "else:\n",
    "    y_all_np = np.asarray(y_all)\n",
    "\n",
    "required_classes = {0, 1, 2}\n",
    "selected_random_state = None\n",
    "\n",
    "for rs in range(201):\n",
    "    gss = GroupShuffleSplit(test_size=0.15, n_splits=1, random_state=rs)\n",
    "    temp_idx, test_idx = next(gss.split(X_all, y_all_np, groups=groups_np))\n",
    "    test_classes = set(np.unique(y_all_np[test_idx]).tolist())\n",
    "\n",
    "    if required_classes.issubset(test_classes):\n",
    "        selected_random_state = rs\n",
    "        break\n",
    "\n",
    "if selected_random_state is None:\n",
    "    raise Exception(\n",
    "        \"Could not find a group-aware split with all classes {0,1,2} in TEST for random_state in [0, 200].\"\n",
    "    )\n",
    "\n",
    "X_temp = X_all[temp_idx]\n",
    "y_temp = y_all[temp_idx]\n",
    "groups_temp = groups_np[temp_idx]\n",
    "\n",
    "X_test = X_all[test_idx]\n",
    "y_test = y_all[test_idx]\n",
    "groups_test = groups_np[test_idx]\n",
    "\n",
    "print(\"Selected random_state:\", selected_random_state)\n",
    "print(\"X_temp:\", X_temp.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "\n",
    "show_class_dist(\"TEMP\", y_temp)\n",
    "show_class_dist(\"TEST\", y_test)\n",
    "\n",
    "print(\"TEMP groups:\", np.unique(groups_temp))\n",
    "print(\"TEST groups:\", np.unique(groups_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "581dc468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: mps\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CSIDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].float()\n",
    "        y = self.y[idx].long()\n",
    "        return x, y\n",
    "\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \\\n",
    "         \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1f2b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len   : 32\n",
      "input_size: 53\n",
      "num_classes: 3\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "seq_len = X_all.shape[1]\n",
    "input_size = X_all.shape[2]\n",
    "num_classes = int(len(torch.unique(y_all)))\n",
    "\n",
    "print(\"seq_len   :\", seq_len)\n",
    "print(\"input_size:\", input_size)\n",
    "print(\"num_classes:\", num_classes)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, num_classes=3, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)   # (B, T, H)\n",
    "        out = out[:, -1, :]     # last timestep\n",
    "        out = self.fc(out)      # (B, C)\n",
    "        return out\n",
    "\n",
    "def train_one_fold(X_train_fold, y_train_fold, X_val_fold, y_val_fold,\n",
    "                   hidden_size=64, num_layers=1, lr=1e-3, epochs=20):\n",
    "    model = LSTMClassifier(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=num_classes\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_ds = CSIDataset(X_train_fold, y_train_fold)\n",
    "    val_ds   = CSIDataset(X_val_fold,   y_val_fold)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ----- train -----\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # ----- val -----\n",
    "        model.eval()\n",
    "        v_correct = 0\n",
    "        v_total = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                logits = model(xb)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                v_correct += (preds == yb).sum().item()\n",
    "                v_total   += yb.size(0)\n",
    "\n",
    "        val_acc = v_correct / v_total\n",
    "\n",
    "        print(f\"  Epoch {epoch:02d} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f}\")\n",
    "\n",
    "    return model, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e612e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== StratifiedGroupKFold on TEMP (85% of data) =====\n",
      "\n",
      "=== Fold 0 ===\n",
      "Train fold size: 119\n",
      "Val   fold size: 18\n",
      "  Epoch 01 | train_acc=0.5798 | val_acc=0.6111\n",
      "  Epoch 02 | train_acc=0.8655 | val_acc=0.5000\n",
      "  Epoch 03 | train_acc=0.8571 | val_acc=0.4444\n",
      "  Epoch 04 | train_acc=0.8824 | val_acc=0.7778\n",
      "  Epoch 05 | train_acc=0.8908 | val_acc=0.7222\n",
      "  Epoch 06 | train_acc=0.8739 | val_acc=0.3333\n",
      "  Epoch 07 | train_acc=0.8571 | val_acc=0.5556\n",
      "  Epoch 08 | train_acc=0.8908 | val_acc=0.6667\n",
      "  Epoch 09 | train_acc=0.8908 | val_acc=0.7222\n",
      "  Epoch 10 | train_acc=0.8908 | val_acc=0.7778\n",
      "  Epoch 11 | train_acc=0.9244 | val_acc=1.0000\n",
      "  Epoch 12 | train_acc=0.9916 | val_acc=0.9444\n",
      "  Epoch 13 | train_acc=0.9916 | val_acc=1.0000\n",
      "  Epoch 14 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 15 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 16 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 17 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 18 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 19 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 20 | train_acc=1.0000 | val_acc=1.0000\n",
      "\n",
      "=== Fold 1 ===\n",
      "Train fold size: 107\n",
      "Val   fold size: 30\n",
      "  Epoch 01 | train_acc=0.3178 | val_acc=0.8667\n",
      "  Epoch 02 | train_acc=0.8785 | val_acc=0.6000\n",
      "  Epoch 03 | train_acc=0.8598 | val_acc=0.8333\n",
      "  Epoch 04 | train_acc=0.8879 | val_acc=0.7667\n",
      "  Epoch 05 | train_acc=0.8972 | val_acc=0.8000\n",
      "  Epoch 06 | train_acc=0.9159 | val_acc=0.8333\n",
      "  Epoch 07 | train_acc=0.9439 | val_acc=0.8000\n",
      "  Epoch 08 | train_acc=0.9626 | val_acc=0.8000\n",
      "  Epoch 09 | train_acc=0.9720 | val_acc=0.8333\n",
      "  Epoch 10 | train_acc=0.9533 | val_acc=0.8333\n",
      "  Epoch 11 | train_acc=0.9813 | val_acc=0.9000\n",
      "  Epoch 12 | train_acc=0.9813 | val_acc=0.8667\n",
      "  Epoch 13 | train_acc=0.9813 | val_acc=0.8333\n",
      "  Epoch 14 | train_acc=0.9907 | val_acc=0.9000\n",
      "  Epoch 15 | train_acc=0.9813 | val_acc=0.8333\n",
      "  Epoch 16 | train_acc=0.9813 | val_acc=0.9000\n",
      "  Epoch 17 | train_acc=0.9907 | val_acc=0.8667\n",
      "  Epoch 18 | train_acc=0.9907 | val_acc=0.9000\n",
      "  Epoch 19 | train_acc=0.9907 | val_acc=0.9333\n",
      "  Epoch 20 | train_acc=0.9907 | val_acc=0.8667\n",
      "\n",
      "=== Fold 2 ===\n",
      "Train fold size: 108\n",
      "Val   fold size: 29\n",
      "  Epoch 01 | train_acc=0.4815 | val_acc=1.0000\n",
      "  Epoch 02 | train_acc=0.8148 | val_acc=0.6207\n",
      "  Epoch 03 | train_acc=0.7685 | val_acc=0.9655\n",
      "  Epoch 04 | train_acc=0.8611 | val_acc=1.0000\n",
      "  Epoch 05 | train_acc=0.9630 | val_acc=0.8966\n",
      "  Epoch 06 | train_acc=0.9259 | val_acc=0.8276\n",
      "  Epoch 07 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 08 | train_acc=0.9907 | val_acc=0.9655\n",
      "  Epoch 09 | train_acc=1.0000 | val_acc=0.9655\n",
      "  Epoch 10 | train_acc=1.0000 | val_acc=0.9655\n",
      "  Epoch 11 | train_acc=0.9815 | val_acc=0.9655\n",
      "  Epoch 12 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 13 | train_acc=0.9907 | val_acc=1.0000\n",
      "  Epoch 14 | train_acc=0.9907 | val_acc=1.0000\n",
      "  Epoch 15 | train_acc=0.9907 | val_acc=1.0000\n",
      "  Epoch 16 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 17 | train_acc=0.9815 | val_acc=1.0000\n",
      "  Epoch 18 | train_acc=0.9722 | val_acc=1.0000\n",
      "  Epoch 19 | train_acc=1.0000 | val_acc=1.0000\n",
      "  Epoch 20 | train_acc=1.0000 | val_acc=1.0000\n",
      "\n",
      "=== Fold 3 ===\n",
      "Train fold size: 114\n",
      "Val   fold size: 23\n",
      "  Epoch 01 | train_acc=0.5088 | val_acc=0.5652\n",
      "  Epoch 02 | train_acc=0.7105 | val_acc=0.4348\n",
      "  Epoch 03 | train_acc=0.8070 | val_acc=0.6087\n",
      "  Epoch 04 | train_acc=0.9035 | val_acc=0.4348\n",
      "  Epoch 05 | train_acc=0.8246 | val_acc=0.4783\n",
      "  Epoch 06 | train_acc=0.8684 | val_acc=0.5217\n",
      "  Epoch 07 | train_acc=0.9035 | val_acc=0.6087\n",
      "  Epoch 08 | train_acc=0.8684 | val_acc=0.5217\n",
      "  Epoch 09 | train_acc=0.9035 | val_acc=0.6522\n",
      "  Epoch 10 | train_acc=0.9298 | val_acc=0.6087\n",
      "  Epoch 11 | train_acc=0.9211 | val_acc=0.6087\n",
      "  Epoch 12 | train_acc=0.9211 | val_acc=0.6522\n",
      "  Epoch 13 | train_acc=0.9298 | val_acc=0.6522\n",
      "  Epoch 14 | train_acc=0.9211 | val_acc=0.6522\n",
      "  Epoch 15 | train_acc=0.9298 | val_acc=0.6522\n",
      "  Epoch 16 | train_acc=0.9298 | val_acc=0.6522\n",
      "  Epoch 17 | train_acc=0.9298 | val_acc=0.6522\n",
      "  Epoch 18 | train_acc=0.9298 | val_acc=0.8261\n",
      "  Epoch 19 | train_acc=0.9912 | val_acc=0.9130\n",
      "  Epoch 20 | train_acc=0.9298 | val_acc=0.6087\n",
      "\n",
      "=== Fold 4 ===\n",
      "Train fold size: 100\n",
      "Val   fold size: 37\n",
      "  Epoch 01 | train_acc=0.5600 | val_acc=0.0000\n",
      "  Epoch 02 | train_acc=0.6000 | val_acc=0.0270\n",
      "  Epoch 03 | train_acc=0.7200 | val_acc=0.6757\n",
      "  Epoch 04 | train_acc=0.8000 | val_acc=0.9189\n",
      "  Epoch 05 | train_acc=0.9300 | val_acc=0.9189\n",
      "  Epoch 06 | train_acc=0.9400 | val_acc=0.8108\n",
      "  Epoch 07 | train_acc=0.9700 | val_acc=0.8649\n",
      "  Epoch 08 | train_acc=0.9500 | val_acc=1.0000\n",
      "  Epoch 09 | train_acc=0.9600 | val_acc=0.9459\n",
      "  Epoch 10 | train_acc=0.9900 | val_acc=0.9730\n",
      "  Epoch 11 | train_acc=0.9700 | val_acc=1.0000\n",
      "  Epoch 12 | train_acc=0.9800 | val_acc=1.0000\n",
      "  Epoch 13 | train_acc=0.9800 | val_acc=0.8919\n",
      "  Epoch 14 | train_acc=0.9700 | val_acc=0.8919\n",
      "  Epoch 15 | train_acc=0.9800 | val_acc=0.9730\n",
      "  Epoch 16 | train_acc=0.9900 | val_acc=0.8649\n",
      "  Epoch 17 | train_acc=0.9900 | val_acc=0.9730\n",
      "  Epoch 18 | train_acc=0.9800 | val_acc=0.9730\n",
      "  Epoch 19 | train_acc=0.9900 | val_acc=1.0000\n",
      "  Epoch 20 | train_acc=0.9900 | val_acc=1.0000\n",
      "\n",
      "Validation accuracy per fold: [1.0, 0.8666666666666667, 1.0, 0.6086956521739131, 1.0]\n",
      "Mean val accuracy over folds: 0.8950724637681159\n",
      "Std  val accuracy over folds: 0.15221559125589618\n",
      "Overlap groups: set()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "K = 5\n",
    "cv = StratifiedGroupKFold(\n",
    "    n_splits=K,\n",
    "    shuffle=True,\n",
    "    random_state=42,  # fix seed เพื่อ reproducible\n",
    ")\n",
    "\n",
    "val_scores = []\n",
    "\n",
    "print(\"===== StratifiedGroupKFold on TEMP (85% of data) =====\")\n",
    "\n",
    "# สำคัญ: ใช้ X_temp, y_temp, groups_temp (ไม่ใช่ X_all)\n",
    "for fold, (tr_idx, va_idx) in enumerate(cv.split(X_temp, y_temp, groups=groups_temp)):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    X_train_fold = X_temp[tr_idx]\n",
    "    y_train_fold = y_temp[tr_idx]\n",
    "    X_val_fold   = X_temp[va_idx]\n",
    "    y_val_fold   = y_temp[va_idx]\n",
    "\n",
    "    print(\"Train fold size:\", len(X_train_fold))\n",
    "    print(\"Val   fold size:\", len(X_val_fold))\n",
    "\n",
    "    _, val_acc = train_one_fold(\n",
    "        X_train_fold, y_train_fold,\n",
    "        X_val_fold,   y_val_fold,\n",
    "        hidden_size=64,\n",
    "        num_layers=1,\n",
    "        lr=1e-3,\n",
    "        epochs=20,\n",
    "    )\n",
    "\n",
    "    val_scores.append(val_acc)\n",
    "\n",
    "print(\"\\nValidation accuracy per fold:\", val_scores)\n",
    "print(\"Mean val accuracy over folds:\", np.mean(val_scores))\n",
    "print(\"Std  val accuracy over folds:\", np.std(val_scores))\n",
    "\n",
    "\n",
    "train_groups = set(groups_temp[tr_idx])\n",
    "val_groups = set(groups_temp[va_idx])\n",
    "\n",
    "intersection = train_groups.intersection(val_groups)\n",
    "\n",
    "print(\"Overlap groups:\", intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34b09012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "input_size = X_temp.shape[2]\n",
    "num_classes = 3\n",
    "EPOCHS = 20          # จะใช้เท่าของเดิมก่อน\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-3            # fix lr ไว้ก่อน ค่อยเล่นทีหลังได้\n",
    "\n",
    "# กำหนดชุด hyperparameters ที่จะลอง\n",
    "hyperparam_configs = [\n",
    "    {\"name\": \"h64_l1\",  \"hidden_size\": 64,  \"num_layers\": 1},\n",
    "    {\"name\": \"h64_l2\",  \"hidden_size\": 64,  \"num_layers\": 2},\n",
    "    {\"name\": \"h128_l1\", \"hidden_size\": 128, \"num_layers\": 1},\n",
    "    {\"name\": \"h128_l2\", \"hidden_size\": 128, \"num_layers\": 2},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2a5929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Config: h64_l1 | hidden=64 | layers=1\n",
      "==============================\n",
      "\n",
      "===== Fold 0 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 0 Epoch 01 | train_acc=0.670 | val_acc=0.750\n",
      "  Fold 0 Epoch 02 | train_acc=0.817 | val_acc=0.857\n",
      "  Fold 0 Epoch 03 | train_acc=0.872 | val_acc=0.893\n",
      "  Fold 0 Epoch 04 | train_acc=0.826 | val_acc=0.857\n",
      "  Fold 0 Epoch 05 | train_acc=0.972 | val_acc=0.893\n",
      "  Fold 0 Epoch 06 | train_acc=0.963 | val_acc=1.000\n",
      "  Fold 0 Epoch 07 | train_acc=0.963 | val_acc=1.000\n",
      "  Fold 0 Epoch 08 | train_acc=0.945 | val_acc=1.000\n",
      "  Fold 0 Epoch 09 | train_acc=0.982 | val_acc=0.929\n",
      "  Fold 0 Epoch 10 | train_acc=0.936 | val_acc=0.964\n",
      "  Fold 0 Epoch 11 | train_acc=0.982 | val_acc=0.964\n",
      "  Fold 0 Epoch 12 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 0 Epoch 13 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 0 Epoch 14 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 0 Epoch 15 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 0 Epoch 16 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 18 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 0 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 1 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 1 Epoch 01 | train_acc=0.651 | val_acc=0.750\n",
      "  Fold 1 Epoch 02 | train_acc=0.807 | val_acc=0.750\n",
      "  Fold 1 Epoch 03 | train_acc=0.807 | val_acc=0.750\n",
      "  Fold 1 Epoch 04 | train_acc=0.853 | val_acc=0.750\n",
      "  Fold 1 Epoch 05 | train_acc=0.844 | val_acc=0.857\n",
      "  Fold 1 Epoch 06 | train_acc=0.881 | val_acc=0.750\n",
      "  Fold 1 Epoch 07 | train_acc=0.899 | val_acc=0.893\n",
      "  Fold 1 Epoch 08 | train_acc=0.899 | val_acc=0.786\n",
      "  Fold 1 Epoch 09 | train_acc=0.927 | val_acc=0.964\n",
      "  Fold 1 Epoch 10 | train_acc=0.982 | val_acc=0.929\n",
      "  Fold 1 Epoch 11 | train_acc=0.945 | val_acc=0.964\n",
      "  Fold 1 Epoch 12 | train_acc=0.945 | val_acc=0.964\n",
      "  Fold 1 Epoch 13 | train_acc=0.991 | val_acc=0.929\n",
      "  Fold 1 Epoch 14 | train_acc=0.972 | val_acc=0.964\n",
      "  Fold 1 Epoch 15 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 16 | train_acc=0.927 | val_acc=0.929\n",
      "  Fold 1 Epoch 17 | train_acc=0.991 | val_acc=0.929\n",
      "  Fold 1 Epoch 18 | train_acc=0.954 | val_acc=0.929\n",
      "  Fold 1 Epoch 19 | train_acc=0.991 | val_acc=0.964\n",
      "  Fold 1 Epoch 20 | train_acc=0.991 | val_acc=0.929\n",
      "\n",
      "===== Fold 2 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 2 Epoch 01 | train_acc=0.536 | val_acc=0.778\n",
      "  Fold 2 Epoch 02 | train_acc=0.800 | val_acc=0.889\n",
      "  Fold 2 Epoch 03 | train_acc=0.855 | val_acc=0.852\n",
      "  Fold 2 Epoch 04 | train_acc=0.864 | val_acc=0.815\n",
      "  Fold 2 Epoch 05 | train_acc=0.864 | val_acc=0.889\n",
      "  Fold 2 Epoch 06 | train_acc=0.864 | val_acc=0.889\n",
      "  Fold 2 Epoch 07 | train_acc=0.873 | val_acc=0.889\n",
      "  Fold 2 Epoch 08 | train_acc=0.882 | val_acc=1.000\n",
      "  Fold 2 Epoch 09 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 10 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 11 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 12 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 14 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 15 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 16 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 3 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 3 Epoch 01 | train_acc=0.582 | val_acc=0.815\n",
      "  Fold 3 Epoch 02 | train_acc=0.855 | val_acc=0.889\n",
      "  Fold 3 Epoch 03 | train_acc=0.873 | val_acc=0.852\n",
      "  Fold 3 Epoch 04 | train_acc=0.891 | val_acc=1.000\n",
      "  Fold 3 Epoch 05 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 3 Epoch 06 | train_acc=0.945 | val_acc=0.889\n",
      "  Fold 3 Epoch 07 | train_acc=0.936 | val_acc=0.889\n",
      "  Fold 3 Epoch 08 | train_acc=0.882 | val_acc=0.889\n",
      "  Fold 3 Epoch 09 | train_acc=0.882 | val_acc=0.889\n",
      "  Fold 3 Epoch 10 | train_acc=0.891 | val_acc=0.963\n",
      "  Fold 3 Epoch 11 | train_acc=0.900 | val_acc=1.000\n",
      "  Fold 3 Epoch 12 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 13 | train_acc=0.918 | val_acc=1.000\n",
      "  Fold 3 Epoch 14 | train_acc=0.973 | val_acc=1.000\n",
      "  Fold 3 Epoch 15 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 16 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 4 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 4 Epoch 01 | train_acc=0.618 | val_acc=0.741\n",
      "  Fold 4 Epoch 02 | train_acc=0.727 | val_acc=0.852\n",
      "  Fold 4 Epoch 03 | train_acc=0.845 | val_acc=0.852\n",
      "  Fold 4 Epoch 04 | train_acc=0.855 | val_acc=0.889\n",
      "  Fold 4 Epoch 05 | train_acc=0.855 | val_acc=0.852\n",
      "  Fold 4 Epoch 06 | train_acc=0.873 | val_acc=0.889\n",
      "  Fold 4 Epoch 07 | train_acc=0.882 | val_acc=0.852\n",
      "  Fold 4 Epoch 08 | train_acc=0.882 | val_acc=0.852\n",
      "  Fold 4 Epoch 09 | train_acc=0.873 | val_acc=0.852\n",
      "  Fold 4 Epoch 10 | train_acc=0.882 | val_acc=0.852\n",
      "  Fold 4 Epoch 11 | train_acc=0.973 | val_acc=0.889\n",
      "  Fold 4 Epoch 12 | train_acc=0.909 | val_acc=0.963\n",
      "  Fold 4 Epoch 13 | train_acc=0.982 | val_acc=0.963\n",
      "  Fold 4 Epoch 14 | train_acc=0.973 | val_acc=0.963\n",
      "  Fold 4 Epoch 15 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 4 Epoch 16 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 4 Epoch 17 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 4 Epoch 18 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 4 Epoch 19 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 4 Epoch 20 | train_acc=1.000 | val_acc=0.963\n",
      "\n",
      ">>> Config h64_l1 fold val accs: [1.0, 0.929, 1.0, 1.0, 0.963]\n",
      ">>> Mean val accuracy: 0.9783 | Std: 0.0287\n",
      "\n",
      "==============================\n",
      "Config: h64_l2 | hidden=64 | layers=2\n",
      "==============================\n",
      "\n",
      "===== Fold 0 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 0 Epoch 01 | train_acc=0.587 | val_acc=0.821\n",
      "  Fold 0 Epoch 02 | train_acc=0.817 | val_acc=0.821\n",
      "  Fold 0 Epoch 03 | train_acc=0.862 | val_acc=0.857\n",
      "  Fold 0 Epoch 04 | train_acc=0.872 | val_acc=0.857\n",
      "  Fold 0 Epoch 05 | train_acc=0.927 | val_acc=0.929\n",
      "  Fold 0 Epoch 06 | train_acc=0.954 | val_acc=0.857\n",
      "  Fold 0 Epoch 07 | train_acc=0.872 | val_acc=0.821\n",
      "  Fold 0 Epoch 08 | train_acc=0.963 | val_acc=1.000\n",
      "  Fold 0 Epoch 09 | train_acc=0.963 | val_acc=0.857\n",
      "  Fold 0 Epoch 10 | train_acc=0.963 | val_acc=0.929\n",
      "  Fold 0 Epoch 11 | train_acc=0.982 | val_acc=0.964\n",
      "  Fold 0 Epoch 12 | train_acc=0.963 | val_acc=0.929\n",
      "  Fold 0 Epoch 13 | train_acc=0.972 | val_acc=0.929\n",
      "  Fold 0 Epoch 14 | train_acc=0.963 | val_acc=0.964\n",
      "  Fold 0 Epoch 15 | train_acc=0.991 | val_acc=0.857\n",
      "  Fold 0 Epoch 16 | train_acc=0.881 | val_acc=0.857\n",
      "  Fold 0 Epoch 17 | train_acc=0.917 | val_acc=0.786\n",
      "  Fold 0 Epoch 18 | train_acc=0.908 | val_acc=0.893\n",
      "  Fold 0 Epoch 19 | train_acc=0.881 | val_acc=1.000\n",
      "  Fold 0 Epoch 20 | train_acc=0.982 | val_acc=0.964\n",
      "\n",
      "===== Fold 1 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 1 Epoch 01 | train_acc=0.734 | val_acc=0.821\n",
      "  Fold 1 Epoch 02 | train_acc=0.862 | val_acc=0.857\n",
      "  Fold 1 Epoch 03 | train_acc=0.890 | val_acc=0.857\n",
      "  Fold 1 Epoch 04 | train_acc=0.881 | val_acc=0.857\n",
      "  Fold 1 Epoch 05 | train_acc=0.890 | val_acc=0.857\n",
      "  Fold 1 Epoch 06 | train_acc=0.927 | val_acc=0.964\n",
      "  Fold 1 Epoch 07 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 08 | train_acc=0.972 | val_acc=0.750\n",
      "  Fold 1 Epoch 09 | train_acc=0.862 | val_acc=0.679\n",
      "  Fold 1 Epoch 10 | train_acc=0.771 | val_acc=0.857\n",
      "  Fold 1 Epoch 11 | train_acc=0.945 | val_acc=0.964\n",
      "  Fold 1 Epoch 12 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 14 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 15 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 16 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 17 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 18 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 19 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 1 Epoch 20 | train_acc=1.000 | val_acc=0.964\n",
      "\n",
      "===== Fold 2 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 2 Epoch 01 | train_acc=0.636 | val_acc=0.704\n",
      "  Fold 2 Epoch 02 | train_acc=0.791 | val_acc=0.852\n",
      "  Fold 2 Epoch 03 | train_acc=0.882 | val_acc=0.852\n",
      "  Fold 2 Epoch 04 | train_acc=0.873 | val_acc=0.815\n",
      "  Fold 2 Epoch 05 | train_acc=0.873 | val_acc=0.963\n",
      "  Fold 2 Epoch 06 | train_acc=0.982 | val_acc=0.926\n",
      "  Fold 2 Epoch 07 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 08 | train_acc=0.964 | val_acc=0.852\n",
      "  Fold 2 Epoch 09 | train_acc=0.809 | val_acc=0.704\n",
      "  Fold 2 Epoch 10 | train_acc=0.927 | val_acc=0.963\n",
      "  Fold 2 Epoch 11 | train_acc=0.918 | val_acc=0.815\n",
      "  Fold 2 Epoch 12 | train_acc=0.882 | val_acc=0.815\n",
      "  Fold 2 Epoch 13 | train_acc=0.882 | val_acc=0.889\n",
      "  Fold 2 Epoch 14 | train_acc=0.882 | val_acc=0.852\n",
      "  Fold 2 Epoch 15 | train_acc=0.882 | val_acc=0.815\n",
      "  Fold 2 Epoch 16 | train_acc=0.882 | val_acc=0.815\n",
      "  Fold 2 Epoch 17 | train_acc=0.882 | val_acc=0.815\n",
      "  Fold 2 Epoch 18 | train_acc=0.882 | val_acc=0.815\n",
      "  Fold 2 Epoch 19 | train_acc=0.882 | val_acc=0.815\n",
      "  Fold 2 Epoch 20 | train_acc=0.882 | val_acc=0.815\n",
      "\n",
      "===== Fold 3 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 3 Epoch 01 | train_acc=0.627 | val_acc=0.741\n",
      "  Fold 3 Epoch 02 | train_acc=0.845 | val_acc=0.963\n",
      "  Fold 3 Epoch 03 | train_acc=0.909 | val_acc=1.000\n",
      "  Fold 3 Epoch 04 | train_acc=0.973 | val_acc=1.000\n",
      "  Fold 3 Epoch 05 | train_acc=0.973 | val_acc=1.000\n",
      "  Fold 3 Epoch 06 | train_acc=0.973 | val_acc=1.000\n",
      "  Fold 3 Epoch 07 | train_acc=0.982 | val_acc=0.926\n",
      "  Fold 3 Epoch 08 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 3 Epoch 09 | train_acc=0.991 | val_acc=0.852\n",
      "  Fold 3 Epoch 10 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 3 Epoch 11 | train_acc=0.982 | val_acc=0.815\n",
      "  Fold 3 Epoch 12 | train_acc=0.945 | val_acc=0.926\n",
      "  Fold 3 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 14 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 15 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 16 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 3 Epoch 17 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 3 Epoch 18 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 3 Epoch 19 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 3 Epoch 20 | train_acc=1.000 | val_acc=0.963\n",
      "\n",
      "===== Fold 4 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 4 Epoch 01 | train_acc=0.555 | val_acc=0.889\n",
      "  Fold 4 Epoch 02 | train_acc=0.864 | val_acc=0.889\n",
      "  Fold 4 Epoch 03 | train_acc=0.873 | val_acc=0.889\n",
      "  Fold 4 Epoch 04 | train_acc=0.873 | val_acc=0.889\n",
      "  Fold 4 Epoch 05 | train_acc=0.873 | val_acc=0.889\n",
      "  Fold 4 Epoch 06 | train_acc=0.955 | val_acc=1.000\n",
      "  Fold 4 Epoch 07 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 4 Epoch 08 | train_acc=0.945 | val_acc=0.889\n",
      "  Fold 4 Epoch 09 | train_acc=0.873 | val_acc=1.000\n",
      "  Fold 4 Epoch 10 | train_acc=0.945 | val_acc=1.000\n",
      "  Fold 4 Epoch 11 | train_acc=0.973 | val_acc=1.000\n",
      "  Fold 4 Epoch 12 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 4 Epoch 13 | train_acc=0.964 | val_acc=1.000\n",
      "  Fold 4 Epoch 14 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 4 Epoch 15 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 4 Epoch 16 | train_acc=0.873 | val_acc=0.889\n",
      "  Fold 4 Epoch 17 | train_acc=0.918 | val_acc=1.000\n",
      "  Fold 4 Epoch 18 | train_acc=0.900 | val_acc=0.889\n",
      "  Fold 4 Epoch 19 | train_acc=0.891 | val_acc=1.000\n",
      "  Fold 4 Epoch 20 | train_acc=0.982 | val_acc=1.000\n",
      "\n",
      ">>> Config h64_l2 fold val accs: [0.964, 0.964, 0.815, 0.963, 1.0]\n",
      ">>> Mean val accuracy: 0.9413 | Std: 0.0648\n",
      "\n",
      "==============================\n",
      "Config: h128_l1 | hidden=128 | layers=1\n",
      "==============================\n",
      "\n",
      "===== Fold 0 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 0 Epoch 01 | train_acc=0.633 | val_acc=0.786\n",
      "  Fold 0 Epoch 02 | train_acc=0.826 | val_acc=0.857\n",
      "  Fold 0 Epoch 03 | train_acc=0.908 | val_acc=1.000\n",
      "  Fold 0 Epoch 04 | train_acc=0.972 | val_acc=1.000\n",
      "  Fold 0 Epoch 05 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 06 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 0 Epoch 07 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 08 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 09 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 0 Epoch 10 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 0 Epoch 11 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 0 Epoch 12 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 14 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 15 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 16 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 1 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 1 Epoch 01 | train_acc=0.697 | val_acc=0.786\n",
      "  Fold 1 Epoch 02 | train_acc=0.872 | val_acc=0.786\n",
      "  Fold 1 Epoch 03 | train_acc=0.872 | val_acc=0.821\n",
      "  Fold 1 Epoch 04 | train_acc=0.908 | val_acc=0.964\n",
      "  Fold 1 Epoch 05 | train_acc=0.917 | val_acc=0.964\n",
      "  Fold 1 Epoch 06 | train_acc=0.982 | val_acc=0.964\n",
      "  Fold 1 Epoch 07 | train_acc=0.991 | val_acc=0.964\n",
      "  Fold 1 Epoch 08 | train_acc=0.991 | val_acc=0.964\n",
      "  Fold 1 Epoch 09 | train_acc=0.982 | val_acc=0.964\n",
      "  Fold 1 Epoch 10 | train_acc=0.991 | val_acc=0.964\n",
      "  Fold 1 Epoch 11 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 12 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 14 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 15 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 16 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 2 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 2 Epoch 01 | train_acc=0.773 | val_acc=0.889\n",
      "  Fold 2 Epoch 02 | train_acc=0.882 | val_acc=0.778\n",
      "  Fold 2 Epoch 03 | train_acc=0.909 | val_acc=0.889\n",
      "  Fold 2 Epoch 04 | train_acc=0.900 | val_acc=0.963\n",
      "  Fold 2 Epoch 05 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 2 Epoch 06 | train_acc=0.900 | val_acc=1.000\n",
      "  Fold 2 Epoch 07 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 08 | train_acc=0.964 | val_acc=1.000\n",
      "  Fold 2 Epoch 09 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 10 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 11 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 2 Epoch 12 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 14 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 15 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 16 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 2 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 3 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 3 Epoch 01 | train_acc=0.545 | val_acc=0.852\n",
      "  Fold 3 Epoch 02 | train_acc=0.800 | val_acc=0.889\n",
      "  Fold 3 Epoch 03 | train_acc=0.955 | val_acc=1.000\n",
      "  Fold 3 Epoch 04 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 05 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 3 Epoch 06 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 07 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 08 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 09 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 10 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 11 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 12 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 14 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 15 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 16 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 4 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 4 Epoch 01 | train_acc=0.745 | val_acc=0.852\n",
      "  Fold 4 Epoch 02 | train_acc=0.855 | val_acc=0.852\n",
      "  Fold 4 Epoch 03 | train_acc=0.864 | val_acc=0.926\n",
      "  Fold 4 Epoch 04 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 4 Epoch 05 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 4 Epoch 06 | train_acc=1.000 | val_acc=0.963\n",
      "  Fold 4 Epoch 07 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 4 Epoch 08 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 09 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 10 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 11 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 12 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 13 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 14 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 15 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 16 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      ">>> Config h128_l1 fold val accs: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      ">>> Mean val accuracy: 1.0 | Std: 0.0\n",
      "\n",
      "==============================\n",
      "Config: h128_l2 | hidden=128 | layers=2\n",
      "==============================\n",
      "\n",
      "===== Fold 0 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 0 Epoch 01 | train_acc=0.606 | val_acc=0.857\n",
      "  Fold 0 Epoch 02 | train_acc=0.826 | val_acc=0.893\n",
      "  Fold 0 Epoch 03 | train_acc=0.945 | val_acc=1.000\n",
      "  Fold 0 Epoch 04 | train_acc=0.963 | val_acc=0.964\n",
      "  Fold 0 Epoch 05 | train_acc=0.982 | val_acc=0.857\n",
      "  Fold 0 Epoch 06 | train_acc=0.872 | val_acc=0.893\n",
      "  Fold 0 Epoch 07 | train_acc=0.908 | val_acc=0.857\n",
      "  Fold 0 Epoch 08 | train_acc=0.890 | val_acc=1.000\n",
      "  Fold 0 Epoch 09 | train_acc=0.954 | val_acc=1.000\n",
      "  Fold 0 Epoch 10 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 0 Epoch 11 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 0 Epoch 12 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 0 Epoch 13 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 0 Epoch 14 | train_acc=0.954 | val_acc=1.000\n",
      "  Fold 0 Epoch 15 | train_acc=0.954 | val_acc=1.000\n",
      "  Fold 0 Epoch 16 | train_acc=1.000 | val_acc=0.964\n",
      "  Fold 0 Epoch 17 | train_acc=0.963 | val_acc=0.964\n",
      "  Fold 0 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 0 Epoch 19 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 0 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 1 =====\n",
      "  Train fold size: 109\n",
      "  Val   fold size: 28\n",
      "  Fold 1 Epoch 01 | train_acc=0.743 | val_acc=0.857\n",
      "  Fold 1 Epoch 02 | train_acc=0.862 | val_acc=0.857\n",
      "  Fold 1 Epoch 03 | train_acc=0.872 | val_acc=0.893\n",
      "  Fold 1 Epoch 04 | train_acc=0.936 | val_acc=0.929\n",
      "  Fold 1 Epoch 05 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 1 Epoch 06 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 1 Epoch 07 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 1 Epoch 08 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 1 Epoch 09 | train_acc=0.991 | val_acc=0.893\n",
      "  Fold 1 Epoch 10 | train_acc=0.716 | val_acc=0.607\n",
      "  Fold 1 Epoch 11 | train_acc=0.661 | val_acc=0.821\n",
      "  Fold 1 Epoch 12 | train_acc=0.862 | val_acc=0.857\n",
      "  Fold 1 Epoch 13 | train_acc=0.890 | val_acc=0.821\n",
      "  Fold 1 Epoch 14 | train_acc=0.890 | val_acc=0.857\n",
      "  Fold 1 Epoch 15 | train_acc=0.890 | val_acc=0.857\n",
      "  Fold 1 Epoch 16 | train_acc=0.917 | val_acc=1.000\n",
      "  Fold 1 Epoch 17 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 18 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 19 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 1 Epoch 20 | train_acc=1.000 | val_acc=1.000\n",
      "\n",
      "===== Fold 2 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 2 Epoch 01 | train_acc=0.718 | val_acc=0.704\n",
      "  Fold 2 Epoch 02 | train_acc=0.873 | val_acc=0.889\n",
      "  Fold 2 Epoch 03 | train_acc=0.945 | val_acc=0.926\n",
      "  Fold 2 Epoch 04 | train_acc=0.927 | val_acc=0.704\n",
      "  Fold 2 Epoch 05 | train_acc=0.955 | val_acc=1.000\n",
      "  Fold 2 Epoch 06 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 2 Epoch 07 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 2 Epoch 08 | train_acc=0.845 | val_acc=0.519\n",
      "  Fold 2 Epoch 09 | train_acc=0.618 | val_acc=0.815\n",
      "  Fold 2 Epoch 10 | train_acc=0.873 | val_acc=0.852\n",
      "  Fold 2 Epoch 11 | train_acc=0.873 | val_acc=0.815\n",
      "  Fold 2 Epoch 12 | train_acc=0.882 | val_acc=0.852\n",
      "  Fold 2 Epoch 13 | train_acc=0.864 | val_acc=0.852\n",
      "  Fold 2 Epoch 14 | train_acc=0.882 | val_acc=0.852\n",
      "  Fold 2 Epoch 15 | train_acc=0.882 | val_acc=0.889\n",
      "  Fold 2 Epoch 16 | train_acc=0.936 | val_acc=1.000\n",
      "  Fold 2 Epoch 17 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 2 Epoch 18 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 2 Epoch 19 | train_acc=0.991 | val_acc=0.963\n",
      "  Fold 2 Epoch 20 | train_acc=0.991 | val_acc=0.963\n",
      "\n",
      "===== Fold 3 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 3 Epoch 01 | train_acc=0.718 | val_acc=0.889\n",
      "  Fold 3 Epoch 02 | train_acc=0.845 | val_acc=0.889\n",
      "  Fold 3 Epoch 03 | train_acc=0.845 | val_acc=0.926\n",
      "  Fold 3 Epoch 04 | train_acc=0.973 | val_acc=1.000\n",
      "  Fold 3 Epoch 05 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 3 Epoch 06 | train_acc=0.964 | val_acc=0.741\n",
      "  Fold 3 Epoch 07 | train_acc=0.791 | val_acc=0.963\n",
      "  Fold 3 Epoch 08 | train_acc=0.927 | val_acc=0.926\n",
      "  Fold 3 Epoch 09 | train_acc=0.882 | val_acc=1.000\n",
      "  Fold 3 Epoch 10 | train_acc=0.973 | val_acc=1.000\n",
      "  Fold 3 Epoch 11 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 12 | train_acc=0.936 | val_acc=1.000\n",
      "  Fold 3 Epoch 13 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 3 Epoch 14 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 15 | train_acc=0.982 | val_acc=1.000\n",
      "  Fold 3 Epoch 16 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 3 Epoch 17 | train_acc=0.818 | val_acc=0.593\n",
      "  Fold 3 Epoch 18 | train_acc=0.609 | val_acc=0.889\n",
      "  Fold 3 Epoch 19 | train_acc=0.836 | val_acc=0.889\n",
      "  Fold 3 Epoch 20 | train_acc=0.882 | val_acc=0.889\n",
      "\n",
      "===== Fold 4 =====\n",
      "  Train fold size: 110\n",
      "  Val   fold size: 27\n",
      "  Fold 4 Epoch 01 | train_acc=0.718 | val_acc=0.889\n",
      "  Fold 4 Epoch 02 | train_acc=0.864 | val_acc=1.000\n",
      "  Fold 4 Epoch 03 | train_acc=0.955 | val_acc=1.000\n",
      "  Fold 4 Epoch 04 | train_acc=0.955 | val_acc=0.889\n",
      "  Fold 4 Epoch 05 | train_acc=0.864 | val_acc=0.852\n",
      "  Fold 4 Epoch 06 | train_acc=0.873 | val_acc=0.852\n",
      "  Fold 4 Epoch 07 | train_acc=0.882 | val_acc=0.889\n",
      "  Fold 4 Epoch 08 | train_acc=0.936 | val_acc=1.000\n",
      "  Fold 4 Epoch 09 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 10 | train_acc=1.000 | val_acc=1.000\n",
      "  Fold 4 Epoch 11 | train_acc=0.918 | val_acc=0.852\n",
      "  Fold 4 Epoch 12 | train_acc=0.855 | val_acc=0.889\n",
      "  Fold 4 Epoch 13 | train_acc=0.927 | val_acc=0.926\n",
      "  Fold 4 Epoch 14 | train_acc=0.945 | val_acc=0.963\n",
      "  Fold 4 Epoch 15 | train_acc=0.955 | val_acc=0.926\n",
      "  Fold 4 Epoch 16 | train_acc=0.964 | val_acc=1.000\n",
      "  Fold 4 Epoch 17 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 4 Epoch 18 | train_acc=0.945 | val_acc=1.000\n",
      "  Fold 4 Epoch 19 | train_acc=0.991 | val_acc=1.000\n",
      "  Fold 4 Epoch 20 | train_acc=0.991 | val_acc=1.000\n",
      "\n",
      ">>> Config h128_l2 fold val accs: [1.0, 1.0, 0.963, 0.889, 1.0]\n",
      ">>> Mean val accuracy: 0.9704 | Std: 0.0432\n",
      "\n",
      "================ FINAL SUMMARY ================\n",
      "\n",
      "h64_l1: hidden=64, layers=1, mean_val_acc=0.9783, std=0.0287\n",
      "h64_l2: hidden=64, layers=2, mean_val_acc=0.9413, std=0.0648\n",
      "h128_l1: hidden=128, layers=1, mean_val_acc=1.0000, std=0.0000\n",
      "h128_l2: hidden=128, layers=2, mean_val_acc=0.9704, std=0.0432\n"
     ]
    }
   ],
   "source": [
    "y_temp_np = y_temp.cpu().numpy() if isinstance(y_temp, torch.Tensor) else np.array(y_temp)\n",
    "\n",
    "results = []  # เอาไว้เก็บผลลัพธ์ของแต่ละ config\n",
    "\n",
    "for cfg in hyperparam_configs:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Config: {cfg['name']} | hidden={cfg['hidden_size']} | layers={cfg['num_layers']}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    # สร้าง KFold ใหม่สำหรับ config นี้ (หรือจะใช้ตัวเดิมก็ได้)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_val_accs = []\n",
    "    fold_idx = 0\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(np.zeros(len(y_temp_np)), y_temp_np):\n",
    "        print(f\"\\n===== Fold {fold_idx} =====\")\n",
    "\n",
    "        X_train_fold = X_temp[train_idx]\n",
    "        y_train_fold = y_temp[train_idx]\n",
    "        X_val_fold   = X_temp[val_idx]\n",
    "        y_val_fold   = y_temp[val_idx]\n",
    "\n",
    "        print(\"  Train fold size:\", len(X_train_fold))\n",
    "        print(\"  Val   fold size:\", len(X_val_fold))\n",
    "\n",
    "        # Dataset / DataLoader\n",
    "        train_ds = CSIDataset(X_train_fold, y_train_fold)\n",
    "        val_ds   = CSIDataset(X_val_fold,   y_val_fold)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # สร้าง model ใหม่สำหรับ fold นี้\n",
    "        model = LSTMClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=cfg[\"hidden_size\"],\n",
    "            num_layers=cfg[\"num_layers\"],\n",
    "            num_classes=num_classes\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        # ===== Train บน fold นี้ =====\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "            model.train()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for xb, yb in train_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == yb).sum().item()\n",
    "                total += yb.size(0)\n",
    "\n",
    "            train_acc = correct / total\n",
    "\n",
    "            # วัด val accuracy\n",
    "            model.eval()\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb = xb.to(DEVICE)\n",
    "                    logits = model(xb)\n",
    "                    preds = logits.argmax(dim=1).cpu()\n",
    "                    val_correct += (preds == yb).sum().item()\n",
    "                    val_total += yb.size(0)\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "\n",
    "            print(f\"  Fold {fold_idx} Epoch {epoch:02d} | train_acc={train_acc:.3f} | val_acc={val_acc:.3f}\")\n",
    "\n",
    "        # ใช้ val_acc ของ epoch สุดท้ายเป็นตัวแทน fold นี้ (เวอร์ชันง่าย)\n",
    "        fold_val_accs.append(val_acc)\n",
    "        fold_idx += 1\n",
    "\n",
    "    mean_val = float(np.mean(fold_val_accs))\n",
    "    std_val  = float(np.std(fold_val_accs))\n",
    "    print(\"\\n>>> Config\", cfg[\"name\"], \"fold val accs:\", [round(a, 3) for a in fold_val_accs])\n",
    "    print(\">>> Mean val accuracy:\", round(mean_val, 4), \"| Std:\", round(std_val, 4))\n",
    "\n",
    "    results.append({\n",
    "        \"name\": cfg[\"name\"],\n",
    "        \"hidden_size\": cfg[\"hidden_size\"],\n",
    "        \"num_layers\": cfg[\"num_layers\"],\n",
    "        \"mean_val_acc\": mean_val,\n",
    "        \"std_val_acc\": std_val,\n",
    "    })\n",
    "\n",
    "print(\"\\n================ FINAL SUMMARY ================\\n\")\n",
    "for r in results:\n",
    "    print(f\"{r['name']}: hidden={r['hidden_size']}, layers={r['num_layers']}, \"\n",
    "          f\"mean_val_acc={r['mean_val_acc']:.4f}, std={r['std_val_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e42ba2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final-Train Epoch 01 | train_acc=0.6788\n",
      "Final-Train Epoch 02 | train_acc=0.8248\n",
      "Final-Train Epoch 03 | train_acc=0.8540\n",
      "Final-Train Epoch 04 | train_acc=0.8759\n",
      "Final-Train Epoch 05 | train_acc=0.9270\n",
      "Final-Train Epoch 06 | train_acc=0.9051\n",
      "Final-Train Epoch 07 | train_acc=1.0000\n",
      "Final-Train Epoch 08 | train_acc=1.0000\n",
      "Final-Train Epoch 09 | train_acc=0.9927\n",
      "Final-Train Epoch 10 | train_acc=1.0000\n",
      "Final-Train Epoch 11 | train_acc=0.9854\n",
      "Final-Train Epoch 12 | train_acc=0.9927\n",
      "Final-Train Epoch 13 | train_acc=1.0000\n",
      "Final-Train Epoch 14 | train_acc=1.0000\n",
      "Final-Train Epoch 15 | train_acc=1.0000\n",
      "Final-Train Epoch 16 | train_acc=1.0000\n",
      "Final-Train Epoch 17 | train_acc=0.9927\n",
      "Final-Train Epoch 18 | train_acc=1.0000\n",
      "Final-Train Epoch 19 | train_acc=1.0000\n",
      "Final-Train Epoch 20 | train_acc=0.9927\n",
      "Final-Train Epoch 21 | train_acc=0.9927\n",
      "Final-Train Epoch 22 | train_acc=0.9927\n",
      "Final-Train Epoch 23 | train_acc=0.9927\n",
      "Final-Train Epoch 24 | train_acc=0.9927\n",
      "Final-Train Epoch 25 | train_acc=0.9927\n",
      "Final-Train Epoch 26 | train_acc=0.9927\n",
      "Final-Train Epoch 27 | train_acc=1.0000\n",
      "Final-Train Epoch 28 | train_acc=0.9927\n",
      "Final-Train Epoch 29 | train_acc=0.9927\n",
      "Final-Train Epoch 30 | train_acc=1.0000\n"
     ]
    }
   ],
   "source": [
    "# สร้าง DataLoader สำหรับ train_full และ test\n",
    "train_full_ds = CSIDataset(X_temp, y_temp)\n",
    "train_full_loader = DataLoader(train_full_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_ds = CSIDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# final model\n",
    "final_model = LSTMClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    num_classes=num_classes\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS_FINAL = 30\n",
    "for epoch in range(1, EPOCHS_FINAL + 1):\n",
    "    final_model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for xb, yb in train_full_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = final_model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Final-Train Epoch {epoch:02d} | train_acc={train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a028e3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Final TEST accuracy: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 5  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 14]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000         5\n",
      "           1     1.0000    1.0000    1.0000        17\n",
      "           2     1.0000    1.0000    1.0000        14\n",
      "\n",
      "    accuracy                         1.0000        36\n",
      "   macro avg     1.0000    1.0000    1.0000        36\n",
      "weighted avg     1.0000    1.0000    1.0000        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final_model.eval()\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        logits = final_model(xb)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_true.extend(yb.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_true = np.array(all_true)\n",
    "\n",
    "test_acc = (all_preds == all_true).mean()\n",
    "print(f\"\\n🎯 Final TEST accuracy: {test_acc:.4f}\\n\")\n",
    "\n",
    "cm = confusion_matrix(all_true, all_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(all_true, all_preds, digits=4))\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
    "plt.xticks(range(num_classes), range(num_classes))\n",
    "plt.yticks(range(num_classes), range(num_classes))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d2efbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to: ../lstm/csi_lstm_group85_test15.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "SAVE_PATH = \"../lstm/csi_lstm_group85_test15.pt\"\n",
    "\n",
    "checkpoint = {\n",
    "    \"model_state_dict\": final_model.state_dict(),\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"class_names\": [\"no_human\", \"static\", \"movement\"],  # ปรับตาม label mapping จริงของคุณ\n",
    "    \"meta\": {\n",
    "        \"split_strategy\": \"GroupShuffleSplit 85/15\",\n",
    "        \"window_size\": obj[\"meta\"][\"window_size\"] if \"meta\" in obj else None,\n",
    "        \"stride_size\": obj[\"meta\"][\"stride_size\"] if \"meta\" in obj else None,\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, SAVE_PATH)\n",
    "\n",
    "print(\"✅ Model saved to:\", SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bf3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi-lstm-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
